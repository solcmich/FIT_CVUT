{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 - balancing & binning (deadline 28. 11. 2020)\n",
    "\n",
    "In short, the main task is to play with balancing and binning to obtain the best results for the binary classification task.\n",
    "  \n",
    "> The instructions are not given in details: It is up to you to come up with ideas on how to fulfill the particular tasks as best you can!\n",
    "\n",
    "## What are you supposed to do:\n",
    "\n",
    "  1. Download the dataset [here](https://www.dropbox.com/s/aq08ytozfplb97b/data.csv?dl=0).\n",
    "  1. Use 2 binning methods (on features of your choice, with your choice of parameters) and comment on its effects on classification performance.\n",
    "  1. Use at least 2 other data balancing techniques of your choice on the dataset and comment the classification results. **Just copied code from tutorial 4 will not be accepted.**\n",
    "  1. Run all classification tests at least three times - once for unbalanced original data, twice for balanced data (try at least 2 balancing techniques), compare those results (give a comment).\n",
    "  \n",
    "Give comments (!) on each step of your solution, with short explanations of your choices.\n",
    "\n",
    "**If you do all this properly, you will obtain 16 points.** \n",
    "\n",
    "## Comments\n",
    "\n",
    "  * Please follow the instructions from https://courses.fit.cvut.cz/MI-PDD/homeworks/index.html.\n",
    "  * If the reviewing teacher is not satisfied, she can (!) give you another chance to rework your homework and to obtain more points. However, this is not a given, so do your best! :)\n",
    "  * English is not compulsory.\n",
    "  \n",
    "## Data description\n",
    "\n",
    "* The dataset can be downloaded [here](https://www.dropbox.com/s/aq08ytozfplb97b/data.csv?dl=0).\n",
    "* The data are devoted to the binary classification task, the aim is to predict the probability that a driver will initiate an auto insurance claim in the next year.\n",
    "* Target feature is called 'y' and signifies whether or not a claim was filed for that policy holder.\n",
    "* To fulfill the task one does not need to know the meaning of predictors.\n",
    "* Predictors that belong to similar groupings are tagged as such in the feature names (e.g., ind, reg, car, calc). In addition, feature names include the postfix bin to indicate binary features and cat to indicate categorical features. Features without these designations are either continuous or ordinal. Values of -1 indicate that the feature was missing from the observation.\n",
    "* While using [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), control the shuffling of data by random_state parameter. Do not use shuffle=False, probably never (can cause systematic error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_log_error, make_scorer, mean_squared_error, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PRECALCULED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>xind_01</th>\n",
       "      <th>xind_02_cat</th>\n",
       "      <th>xind_03</th>\n",
       "      <th>xind_04_cat</th>\n",
       "      <th>xind_05_cat</th>\n",
       "      <th>xind_06_bin</th>\n",
       "      <th>xind_07_bin</th>\n",
       "      <th>xind_08_bin</th>\n",
       "      <th>xind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>xcalc_11</th>\n",
       "      <th>xcalc_12</th>\n",
       "      <th>xcalc_13</th>\n",
       "      <th>xcalc_14</th>\n",
       "      <th>xcalc_15_bin</th>\n",
       "      <th>xcalc_16_bin</th>\n",
       "      <th>xcalc_17_bin</th>\n",
       "      <th>xcalc_18_bin</th>\n",
       "      <th>xcalc_19_bin</th>\n",
       "      <th>xcalc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>469726</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36552</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215010</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42384</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        y  xind_01  xind_02_cat  xind_03  xind_04_cat  xind_05_cat  \\\n",
       "469726  0        3            1        9            0            0   \n",
       "36552   0        1            1        8            0            0   \n",
       "250120  0        0            1        3            0            0   \n",
       "215010  0        2            1        3            1            0   \n",
       "42384   0        1            1        8            0            0   \n",
       "\n",
       "        xind_06_bin  xind_07_bin  xind_08_bin  xind_09_bin  ...  xcalc_11  \\\n",
       "469726            1            0            0            0  ...         4   \n",
       "36552             1            0            0            0  ...         6   \n",
       "250120            1            0            0            0  ...         6   \n",
       "215010            0            1            0            0  ...         4   \n",
       "42384             1            0            0            0  ...         2   \n",
       "\n",
       "        xcalc_12  xcalc_13  xcalc_14  xcalc_15_bin  xcalc_16_bin  \\\n",
       "469726         2         6         5             0             1   \n",
       "36552          1         3        10             1             1   \n",
       "250120         0         4         9             0             0   \n",
       "215010         2         4         5             0             1   \n",
       "42384          4         4         9             0             1   \n",
       "\n",
       "        xcalc_17_bin  xcalc_18_bin  xcalc_19_bin  xcalc_20_bin  \n",
       "469726             1             1             0             0  \n",
       "36552              1             0             1             0  \n",
       "250120             1             0             0             0  \n",
       "215010             1             0             1             0  \n",
       "42384              1             0             1             0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>xind_01</th>\n",
       "      <th>xind_02_cat</th>\n",
       "      <th>xind_03</th>\n",
       "      <th>xind_04_cat</th>\n",
       "      <th>xind_05_cat</th>\n",
       "      <th>xind_06_bin</th>\n",
       "      <th>xind_07_bin</th>\n",
       "      <th>xind_08_bin</th>\n",
       "      <th>xind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>xcalc_11</th>\n",
       "      <th>xcalc_12</th>\n",
       "      <th>xcalc_13</th>\n",
       "      <th>xcalc_14</th>\n",
       "      <th>xcalc_15_bin</th>\n",
       "      <th>xcalc_16_bin</th>\n",
       "      <th>xcalc_17_bin</th>\n",
       "      <th>xcalc_18_bin</th>\n",
       "      <th>xcalc_19_bin</th>\n",
       "      <th>xcalc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.036448</td>\n",
       "      <td>1.900378</td>\n",
       "      <td>1.358943</td>\n",
       "      <td>4.423318</td>\n",
       "      <td>0.416794</td>\n",
       "      <td>0.405188</td>\n",
       "      <td>0.393742</td>\n",
       "      <td>0.257033</td>\n",
       "      <td>0.163921</td>\n",
       "      <td>0.185304</td>\n",
       "      <td>...</td>\n",
       "      <td>5.441382</td>\n",
       "      <td>1.441918</td>\n",
       "      <td>2.872288</td>\n",
       "      <td>7.539026</td>\n",
       "      <td>0.122427</td>\n",
       "      <td>0.627840</td>\n",
       "      <td>0.554182</td>\n",
       "      <td>0.287182</td>\n",
       "      <td>0.349024</td>\n",
       "      <td>0.153318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.187401</td>\n",
       "      <td>1.983789</td>\n",
       "      <td>0.664594</td>\n",
       "      <td>2.699902</td>\n",
       "      <td>0.493311</td>\n",
       "      <td>1.350642</td>\n",
       "      <td>0.488579</td>\n",
       "      <td>0.436998</td>\n",
       "      <td>0.370205</td>\n",
       "      <td>0.388544</td>\n",
       "      <td>...</td>\n",
       "      <td>2.332871</td>\n",
       "      <td>1.202963</td>\n",
       "      <td>1.694887</td>\n",
       "      <td>2.746652</td>\n",
       "      <td>0.327779</td>\n",
       "      <td>0.483381</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>0.452447</td>\n",
       "      <td>0.476662</td>\n",
       "      <td>0.360295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   y        xind_01    xind_02_cat        xind_03  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.036448       1.900378       1.358943       4.423318   \n",
       "std         0.187401       1.983789       0.664594       2.699902   \n",
       "min         0.000000       0.000000      -1.000000       0.000000   \n",
       "25%         0.000000       0.000000       1.000000       2.000000   \n",
       "50%         0.000000       1.000000       1.000000       4.000000   \n",
       "75%         0.000000       3.000000       2.000000       6.000000   \n",
       "max         1.000000       7.000000       4.000000      11.000000   \n",
       "\n",
       "         xind_04_cat    xind_05_cat    xind_06_bin    xind_07_bin  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.416794       0.405188       0.393742       0.257033   \n",
       "std         0.493311       1.350642       0.488579       0.436998   \n",
       "min        -1.000000      -1.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       0.000000       1.000000       1.000000   \n",
       "max         1.000000       6.000000       1.000000       1.000000   \n",
       "\n",
       "         xind_08_bin    xind_09_bin  ...       xcalc_11       xcalc_12  \\\n",
       "count  595212.000000  595212.000000  ...  595212.000000  595212.000000   \n",
       "mean        0.163921       0.185304  ...       5.441382       1.441918   \n",
       "std         0.370205       0.388544  ...       2.332871       1.202963   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       4.000000       1.000000   \n",
       "50%         0.000000       0.000000  ...       5.000000       1.000000   \n",
       "75%         0.000000       0.000000  ...       7.000000       2.000000   \n",
       "max         1.000000       1.000000  ...      19.000000      10.000000   \n",
       "\n",
       "            xcalc_13       xcalc_14   xcalc_15_bin   xcalc_16_bin  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        2.872288       7.539026       0.122427       0.627840   \n",
       "std         1.694887       2.746652       0.327779       0.483381   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         2.000000       6.000000       0.000000       0.000000   \n",
       "50%         3.000000       7.000000       0.000000       1.000000   \n",
       "75%         4.000000       9.000000       0.000000       1.000000   \n",
       "max        13.000000      23.000000       1.000000       1.000000   \n",
       "\n",
       "        xcalc_17_bin   xcalc_18_bin   xcalc_19_bin   xcalc_20_bin  \n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000  \n",
       "mean        0.554182       0.287182       0.349024       0.153318  \n",
       "std         0.497056       0.452447       0.476662       0.360295  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         1.000000       0.000000       0.000000       0.000000  \n",
       "75%         1.000000       1.000000       1.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.sample(5))\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning\n",
    "\n",
    "Use 2 binning methods (on features of your choice, with your choice of parameters) and comment on its effects on classification performance.\n",
    "\n",
    "Binning is used for continuous variable discretization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect the variables to apply binning to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuos_cols_mask = [not ('bin' in x or 'cat' in x or x=='y') for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['xind_01', 'xind_03', 'xind_14', 'xind_15', 'xreg_01', 'xreg_02',\n",
       "       'xreg_03', 'xcar_11', 'xcar_12', 'xcar_13', 'xcar_14', 'xcar_15',\n",
       "       'xcalc_01', 'xcalc_02', 'xcalc_03', 'xcalc_04', 'xcalc_05', 'xcalc_06',\n",
       "       'xcalc_07', 'xcalc_08', 'xcalc_09', 'xcalc_10', 'xcalc_11', 'xcalc_12',\n",
       "       'xcalc_13', 'xcalc_14'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[continuos_cols_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_bins(c):\n",
    "    uniques = c.nunique()\n",
    "    # Square root choice\n",
    "    return int(np.ceil(uniques**(1/2)))\n",
    "\n",
    "def get_binning(df, cols, method):\n",
    "    for c in cols:\n",
    "        n = num_bins(df[c])\n",
    "        df[c] = method(df[c], n, duplicates='drop').cat.codes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df.copy()\n",
    "cut = get_binning(df_c, df_c.columns[continuos_cols_mask], pd.cut)\n",
    "df_c = df.copy()\n",
    "qcut = get_binning(df_c, df_c.columns[continuos_cols_mask], pd.qcut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original data \n",
      "Accuracy:  0.9190835205913854 \n",
      "F1-score:  0.05382839742645253\n",
      "Cut data \n",
      "Accuracy:  0.9157065753827415 \n",
      "F1-score:  0.056952210892345284\n",
      "Qcut data \n",
      "Accuracy:  0.9149379423315203 \n",
      "F1-score:  0.05496966868875408\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('y', axis=1)\n",
    "y = df.y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=0)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "print('\\nOriginal data \\nAccuracy: ', accuracy_score(y_test, y_pred),'\\nF1-score: ', f1_score(y_test, y_pred))\n",
    "\n",
    "X = cut.drop('y', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=0)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "print('Cut data \\nAccuracy: ', accuracy_score(y_test, y_pred),'\\nF1-score: ', f1_score(y_test, y_pred))\n",
    "\n",
    "X = qcut.drop('y', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=0)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "print('Qcut data \\nAccuracy: ', accuracy_score(y_test, y_pred),'\\nF1-score: ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used 2 binning methods \n",
    "<li><b>cut</b>, which is method to split data into bins with equal width\n",
    "<li><b>qcut</b>, which is method to split data into bins with equal depth\n",
    "As bins count, we used <b> Square root choice</b> method \n",
    "We can see, that the F-1 score is really low, this is probably because the data are unbalanced (the distribution of y is far from 50/50), we will check this in part two.\n",
    "\n",
    "The f-score is overally low, but we can see slight improvement with the \"cut\" approach. We might achieve better score if we changed categorical data to one hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data balancing\n",
    "Use at least 2 other data balancing techniques of your choice on the dataset and comment the classification results. Just copied code from tutorial 4 will not be accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution in target var: \n",
      " 1 - 96.4 % \n",
      " 0 - 3.6 %\n"
     ]
    }
   ],
   "source": [
    "total = df.y.count()\n",
    "pos = df[df.y == 0].y.count()\n",
    "neg = df[df.y == 1].y.count()\n",
    "print(f'Distribution in target var: \\n 1 - {round(100*pos/total, 1)} % \\n 0 - {round(100*neg/total, 1)} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of following methods, first two as undersampling and the third as oversampling\n",
    "- One-side Sampling (OSS)\n",
    "- Neighborhood Cleaning Rule (NCL) \n",
    "- SMOTE\n",
    "- Random over sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-side Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 score: 0.05188243866893369\n"
     ]
    }
   ],
   "source": [
    "if not USE_PRECALCULED:\n",
    "    from imblearn.under_sampling import OneSidedSelection\n",
    "    oss = OneSidedSelection()\n",
    "    X = df.drop('y', axis=1)\n",
    "    y = df.y\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=0)\n",
    "    y_pred = oss.fit_sample(X_train, y_train)\n",
    "    Counter(y_pred[1])\n",
    "    clf.fit(y_pred[0], y_pred[1])\n",
    "    predict = clf.predict(X_test)\n",
    "    f1 = f1_score(y_test, predict)\n",
    "    print(f'\\nF1 score: {f1}')\n",
    "else:\n",
    "    print(f'\\nF1 score: 0.05188243866893369')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbourhood cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 309880, 1: 12844})\n",
      "F1 score: 0.05619069659800972\n"
     ]
    }
   ],
   "source": [
    "if not USE_PRECALCULED: \n",
    "    from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "    ncl = NeighbourhoodCleaningRule()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=0)\n",
    "    y_pred = ncl.fit_sample(X_train, y_train)\n",
    "    print(Counter(y_pred[1]))\n",
    "    clf.fit(y_pred[0], y_pred[1])\n",
    "    predict = clf.predict(X_test)\n",
    "    f1 = f1_score(y_test, predict)\n",
    "    print(f'\\nF1 score: {f1}')\n",
    "else:\n",
    "    print('Counter({0: 309880, 1: 12844})')\n",
    "    print('F1 score: 0.05619069659800972')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 344283, 1: 344283})\n"
     ]
    }
   ],
   "source": [
    "if not USE_PRECALCULED:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    smt = SMOTE()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=0)\n",
    "    y_pred = smt.fit_sample(X_train, y_train)\n",
    "    print(Counter(y_pred[1]))\n",
    "else:\n",
    "    print('Counter({0: 344283, 1: 344283})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 score: 0.058004640371229696\n"
     ]
    }
   ],
   "source": [
    "if not USE_PRECALCULED:\n",
    "    clf.fit(y_pred[0], y_pred[1])\n",
    "    predict = clf.predict(X_test)\n",
    "    f1 = f1_score(y_test, predict)\n",
    "    print(f'\\nF1 score: {f1}')\n",
    "else:\n",
    "    print(f'\\nF1 score: 0.058004640371229696')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 344283, 1: 344283})\n",
      "F1 score: 0.04985176238058636\n"
     ]
    }
   ],
   "source": [
    "if not USE_PRECALCULED:\n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    ros = RandomOverSampler()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=0)\n",
    "    y_pred = ros.fit_sample(X_train, y_train)\n",
    "    print(Counter(y_pred[1]))\n",
    "    clf.fit(y_pred[0], y_pred[1])\n",
    "    predict = clf.predict(X_test)\n",
    "    f1 = f1_score(y_test, predict)\n",
    "    print(f'\\nF1 score: {f1}')\n",
    "else:\n",
    "    print('Counter({0: 344283, 1: 344283})')\n",
    "    print('F1 score: 0.04985176238058636')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, best method for this imbalanced dataset is SMOTE. This dataset was very imbalanced overall, thus the f score is really low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
