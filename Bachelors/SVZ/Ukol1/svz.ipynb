{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import knihoven a konfigurace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from pypylon import pylon \n",
    "from pypylon_opencv_viewer import BaslerOpenCVViewer\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "\n",
    "import yaml\n",
    "from natsort import natsorted\n",
    "from scipy.spatial import distance\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pomocné funkce\n",
    "Z následujících funkcí je potřeba vybírat ty vhodné pro splnění úkolu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='connect_functions'>Funkce k připojení kamery podle sériového čísla.</a> Umožňuje poté tlačítkem zapnout snímání aktuální scény. V případě nutnosti změny nastavení připojení kamery, je třeba restartovat jupyter notebook tlačítkem `restart kernel (with dialog)`. Kamera se bude tvářit jako, že je již připojená k jinému zařízení. (`RuntimeException: Failed to open 'Basler ...'. The device is controlled by another application.`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Configuration PyPylon Viewer to load features for RGB Matrix Camera\n",
    "VIEWER_CONFIG_RGB_MATRIX = {\n",
    "    \"features\": [\n",
    "        {\n",
    "            \"name\": \"GainRaw\",\n",
    "            \"type\": \"int\",\n",
    "            \"step\": 1,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Height\",\n",
    "            \"type\": \"int\",\n",
    "            \"unit\": \"px\",\n",
    "            \"step\": 2,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Width\",\n",
    "            \"type\": \"int\",\n",
    "            \"unit\": \"px\",\n",
    "            \"step\": 2,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CenterX\",\n",
    "            \"type\": \"bool\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CenterY\",\n",
    "            \"type\": \"bool\",\n",
    "\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"OffsetX\",\n",
    "            \"type\": \"int\",\n",
    "            \"dependency\": {\"CenterX\": False},\n",
    "            \"unit\": \"px\",\n",
    "            \"step\": 2,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"OffsetY\",\n",
    "            \"type\": \"int\",\n",
    "            \"dependency\": {\"CenterY\": False},\n",
    "            \"unit\": \"px\",\n",
    "            \"step\": 2,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"AcquisitionFrameRateAbs\",\n",
    "            \"type\": \"int\",\n",
    "            \"unit\": \"fps\",\n",
    "            \"dependency\": {\"AcquisitionFrameRateEnable\": True},\n",
    "            \"value\": 30,\n",
    "            \"max\": 150,\n",
    "            \"min\": 1,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"AcquisitionFrameRateEnable\",\n",
    "            \"type\": \"bool\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ExposureAuto\",\n",
    "            \"type\": \"choice_text\",\n",
    "            \"options\": [\"Off\", \"Once\", \"Continuous\"],\n",
    "            \"style\": {\"button_width\": \"90px\"}\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ExposureTimeAbs\",\n",
    "            \"type\": \"int\",\n",
    "            \"dependency\": {\"ExposureAuto\": \"Off\"},\n",
    "            \"unit\": \"μs\",\n",
    "            \"step\": 100,\n",
    "            \"max\": 35000,\n",
    "            \"min\": 500,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"BalanceWhiteAuto\",\n",
    "            \"type\": \"choice_text\",\n",
    "            \"options\": [\"Off\", \"Once\", \"Continuous\"],\n",
    "            \"style\": {\"button_width\": \"90px\"}\n",
    "        },\n",
    "    ],\n",
    "    \"features_layout\": [\n",
    "        (\"Height\", \"Width\"), \n",
    "        (\"OffsetX\", \"CenterX\"), \n",
    "        (\"OffsetY\", \"CenterY\"), \n",
    "        (\"ExposureAuto\", \"ExposureTimeAbs\"),\n",
    "        (\"AcquisitionFrameRateAbs\", \"AcquisitionFrameRateEnable\"),\n",
    "        (\"BalanceWhiteAuto\", \"GainRaw\")\n",
    "    ],\n",
    "    \"actions_layout\": [\n",
    "        (\"StatusLabel\"),\n",
    "        (\"SaveConfig\", \"LoadConfig\", \"ContinuousShot\", \"SingleShot\"), \n",
    "        (\"UserSet\")\n",
    "    ],\n",
    "    \"default_user_set\": \"UserSet3\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Configuration PyPylon Viewer to load features for Monochromatic Matrix Camera\n",
    "VIEWER_CONFIG_MONO_MATRIX = {\n",
    "    \"features\": [\n",
    "         {\n",
    "            \"name\": \"GainRaw\",\n",
    "            \"type\": \"int\",\n",
    "            \"step\": 1,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Height\",\n",
    "            \"type\": \"int\",\n",
    "            \"unit\": \"px\",\n",
    "            \"step\": 2,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Width\",\n",
    "            \"type\": \"int\",\n",
    "            \"unit\": \"px\",\n",
    "            \"step\": 2,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CenterX\",\n",
    "            \"type\": \"bool\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CenterY\",\n",
    "            \"type\": \"bool\",\n",
    "\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"OffsetX\",\n",
    "            \"type\": \"int\",\n",
    "            \"dependency\": {\"CenterX\": False},\n",
    "            \"unit\": \"px\",\n",
    "            \"step\": 2,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"OffsetY\",\n",
    "            \"type\": \"int\",\n",
    "            \"dependency\": {\"CenterY\": False},\n",
    "            \"unit\": \"px\",\n",
    "            \"step\": 2,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"AcquisitionFrameRateAbs\",\n",
    "            \"type\": \"int\",\n",
    "            \"unit\": \"fps\",\n",
    "            \"dependency\": {\"AcquisitionFrameRateEnable\": True},\n",
    "            \"value\": 30,\n",
    "            \"max\": 150,\n",
    "            \"min\": 1,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"AcquisitionFrameRateEnable\",\n",
    "            \"type\": \"bool\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ExposureAuto\",\n",
    "            \"type\": \"choice_text\",\n",
    "            \"options\": [\"Off\", \"Once\", \"Continuous\"],\n",
    "            \"style\": {\"button_width\": \"90px\"}\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ExposureTimeAbs\",\n",
    "            \"type\": \"int\",\n",
    "            \"dependency\": {\"ExposureAuto\": \"Off\"},\n",
    "            \"unit\": \"μs\",\n",
    "            \"step\": 500,\n",
    "            \"max\": 35000,\n",
    "            \"min\": 500,\n",
    "        },\n",
    "    ],\n",
    "    \"features_layout\": [\n",
    "        (\"Height\", \"Width\"), \n",
    "        (\"OffsetX\", \"CenterX\"), \n",
    "        (\"OffsetY\", \"CenterY\"), \n",
    "        (\"ExposureTimeAbs\", \"ExposureAuto\"),\n",
    "        (\"AcquisitionFrameRateAbs\", \"AcquisitionFrameRateEnable\"),\n",
    "        (\"GainRaw\")\n",
    "    ],\n",
    "    \"actions_layout\": [\n",
    "        (\"StatusLabel\"),\n",
    "        (\"SaveConfig\", \"LoadConfig\", \"ContinuousShot\", \"SingleShot\"), \n",
    "        (\"UserSet\")\n",
    "    ],\n",
    "    \"default_user_set\": \"UserSet3\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Configuration PyPylon Viewer to load features for Monochromatic Line Scan Camera\n",
    "VIEWER_CONFIG_MONO_LINE = {\n",
    "    \"features\": [\n",
    "         {\n",
    "            \"name\": \"GainRaw\",\n",
    "            \"type\": \"int\",\n",
    "            \"step\": 1,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Height\",\n",
    "            \"type\": \"int\",\n",
    "            \"unit\": \"px\",\n",
    "            \"step\": 2,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Width\",\n",
    "            \"type\": \"int\",\n",
    "            \"unit\": \"px\",\n",
    "            \"step\": 2,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CenterX\",\n",
    "            \"type\": \"bool\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"OffsetX\",\n",
    "            \"type\": \"int\",\n",
    "            \"dependency\": {\"CenterX\": False},\n",
    "            \"unit\": \"px\",\n",
    "            \"step\": 2,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"AcquisitionLineRateAbs\",\n",
    "            \"type\": \"int\",\n",
    "            \"max\": 5000,\n",
    "            \"min\": 100,\n",
    "            \"step\": 100,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ExposureAuto\",\n",
    "            \"type\": \"choice_text\",\n",
    "            \"options\": [\"Off\", \"Once\", \"Continuous\"],\n",
    "            \"style\": {\"button_width\": \"90px\"}\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ExposureTimeAbs\",\n",
    "            \"type\": \"int\",\n",
    "            \"dependency\": {\"ExposureAuto\": \"Off\"},\n",
    "            \"unit\": \"μs\",\n",
    "            \"step\": 500,\n",
    "            \"max\": 35000,\n",
    "            \"min\": 500,\n",
    "        },\n",
    "    ],\n",
    "    \"features_layout\": [\n",
    "        (\"Height\", \"Width\"), \n",
    "        (\"OffsetX\", \"CenterX\"), \n",
    "        (\"ExposureTimeAbs\", \"ExposureAuto\"),\n",
    "        (\"AcquisitionLineRateAbs\", \"GainRaw\")\n",
    "    ],\n",
    "    \"actions_layout\": [\n",
    "        (\"StatusLabel\"),\n",
    "        (\"SaveConfig\", \"LoadConfig\", \"ContinuousShot\", \"SingleShot\"), \n",
    "        (\"UserSet\")\n",
    "    ],\n",
    "    \"default_user_set\": \"UserSet3\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Configuration PyPylon Viewer to load features for Monochromatic Matrix Camera with pericentric lens\n",
    "VIEWER_CONFIG_MONO_MATRIX_PERICENTRIC = {\n",
    "    \"features\": [\n",
    "         {\n",
    "            \"name\": \"Gain\",\n",
    "            \"type\": \"int\",\n",
    "            \"unit\": \"dB\",\n",
    "            \"step\": 1,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Height\",\n",
    "            \"type\": \"int\",\n",
    "            \"unit\": \"px\",\n",
    "            \"step\": 2,\n",
    "            \"value\": 1270\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Width\",\n",
    "            \"type\": \"int\",\n",
    "            \"unit\": \"px\",\n",
    "            \"step\": 2,\n",
    "            \"value\": 1344\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"OffsetX\",\n",
    "            \"type\": \"int\",\n",
    "            \"unit\": \"px\",\n",
    "            \"step\": 2,\n",
    "            \"value\": 608\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"OffsetY\",\n",
    "            \"type\": \"int\",\n",
    "            \"unit\": \"px\",\n",
    "            \"step\": 2,\n",
    "            \"value\": 418\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ExposureTime\",\n",
    "            \"type\": \"int\",\n",
    "            \"max\": 35000,\n",
    "            \"min\": 90,\n",
    "            \"step\": 30,\n",
    "            \"value\": 1500,\n",
    "            \"unit\": \"μs\",\n",
    "        },\n",
    "    ],\n",
    "    \"features_layout\": [\n",
    "        (\"Height\", \"Width\"), \n",
    "        (\"OffsetX\", \"OffsetY\"), \n",
    "        (\"Gain\", \"ExposureTime\"),\n",
    "    ],\n",
    "    \"actions_layout\": [\n",
    "        (\"StatusLabel\"),\n",
    "        (\"SaveConfig\", \"LoadConfig\", \"ContinuousShot\", \"SingleShot\"), \n",
    "        (\"UserSet\")\n",
    "    ],\n",
    "    \"default_user_set\": \"UserSet3\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def connect_camera(serial_number):\n",
    "    ''' Connects camera specified with its serial number\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    serial_number : string\n",
    "        Camera's serial number.\n",
    "    grabbed_images_path : string\n",
    "        Path to folder where the saved images will be stored.\n",
    "    Returns\n",
    "    -------\n",
    "    camera : object\n",
    "    '''\n",
    "    info = None\n",
    "    for i in pylon.TlFactory.GetInstance().EnumerateDevices():\n",
    "        if i.GetSerialNumber() == serial_number:\n",
    "            info = i\n",
    "            break\n",
    "    else:\n",
    "        print('Camera with {} serial number not found'.format(serial_number))\n",
    "\n",
    "    # VERY IMPORTANT STEP! To use Basler PyPylon OpenCV viewer you have to call .Open() method on you camera\n",
    "    if info is not None:\n",
    "        camera = pylon.InstantCamera(pylon.TlFactory.GetInstance().CreateDevice(info)) \n",
    "        camera.Open()\n",
    "        return camera\n",
    "    else:\n",
    "        return None    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load_save_functions'>Funkce pro načtení/uložení obrázku</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     4
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def load_image(file_path):\n",
    "    assert os.path.exists(file_path), 'File does NOT exist! (' + file_path + ')'\n",
    "    return cv2.imread(file_path)\n",
    "\n",
    "def save_image(image, file_path):\n",
    "    return cv2.imwrite(file_path, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkce pro zobrazení okna s přidáním eventu na klik myší."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def show_camera_window(*imgs, scale=1):\n",
    "    def print_xy(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONUP:\n",
    "            print('x = %d, y = %d'% (x, y))  \n",
    "        \n",
    "    for i, img in enumerate(imgs, 1):\n",
    "        window_name_id = 'Camera capture' + ' ' + str(i)\n",
    "        \n",
    "        h,w = img.shape[:2]\n",
    "        cv2.namedWindow(window_name_id, cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)\n",
    "        cv2.resizeWindow(window_name_id, int(w * scale), int(h * scale))\n",
    "        cv2.setMouseCallback(window_name_id, print_xy)\n",
    "        if len(imgs) > 1:\n",
    "            cv2.moveWindow(window_name_id, (i-1)*int(w * scale), 0)\n",
    "        cv2.imshow(window_name_id, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preprocessing_functions'>Metody předzpracování.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-18T09:33:19.139Z"
    },
    "code_folding": [
     0,
     15,
     29,
     43,
     57,
     96,
     115,
     148
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def to_gray(img_bgr):\n",
    "    ''' Converts image to monochrome\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    if len(img_bgr.shape) == 2:\n",
    "        return img_bgr\n",
    "    return cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def to_hsv(img_bgr):\n",
    "    ''' Converts image to HSV (hue, saturation, value) color space.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    dst = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "    return dst\n",
    "\n",
    "def to_rgb(img_bgr):\n",
    "    ''' Converts image to RGB (red, green, blue) color space from BGR.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    dst = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    return dst\n",
    "\n",
    "def negative(img):\n",
    "    ''' Converts image to its negative.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    dst = 255 - img\n",
    "    return dst\n",
    "\n",
    "def crop(img, tl_x, tl_y, br_x, br_y):\n",
    "    ''' Crops image by added coordinates.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    tl_x : int\n",
    "        TOP-LEFT corner's x-coordinate\n",
    "    tl_y : int\n",
    "        TOP-LEFT corner's y-coordinate\n",
    "    br_x : int\n",
    "        BOTTOM-RIGHT corner's x-coordinate\n",
    "    br_y : int\n",
    "        BOTTOM-RIGHT corner's y-coordinate\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    roi = img[tl_y:br_y, tl_x:br_x]\n",
    "    return roi    \n",
    "\n",
    "def crop_by_bounding_rect(img_bin):\n",
    "    ''' Crops binary image by ONE bounding rectangle corresponding to ALL objects in the binary image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_bin : numpy.ndarray\n",
    "        Input binary image.\n",
    "    Returns\n",
    "    -------\n",
    "    Output cropped image.\n",
    "    '''\n",
    "    assert len(img_bin.shape) == 2, 'Input image is NOT binary!'\n",
    "    \n",
    "    contours, _  = cv2.findContours(img_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    tl_x, tl_y, w, h = cv2.boundingRect(contours[0])\n",
    "    return crop(img_bin, tl_x, tl_y, tl_x+w, tl_y+h)\n",
    "\n",
    "def crop_contour(contour, image):\n",
    "    ''' Crops contour in respect to its bounding rectangle. \n",
    "    It's the fastest method, but could include other parts \n",
    "    of image than just contour if the contour is irregulary shaped.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    contour : numpy.ndarray\n",
    "        Contour that represents the area from image to be cropped. \n",
    "        The bounding rectangle of contour is used.\n",
    "    img_bin : numpy.ndarray\n",
    "        Input binary image.\n",
    "    Returns\n",
    "    -------\n",
    "    Output cropped image.\n",
    "    '''\n",
    "    x,y,w,h = cv2.boundingRect(contour)\n",
    "    return image[y:y+h, x:x+w]\n",
    "\n",
    "def contour_to_image(contour, image, size=None):\n",
    "    ''' Creates new image from the contour. \n",
    "    It's similar to contour cropping but it's not that fast. \n",
    "    It does not suffer from the known error if the contour is irregulary shaped.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    contour : numpy.ndarray\n",
    "        Contour that represents the area from image to be cropped. \n",
    "    img_bin : numpy.ndarray\n",
    "        Input binary image.\n",
    "    size : tuple\n",
    "        Optional size of the created image. \n",
    "        If it's not used, the image's size is the same as the \n",
    "        size of bounding rectangle of the input contour.\n",
    "    Returns\n",
    "    -------\n",
    "    Output cropped image.\n",
    "    '''\n",
    "    if size is None:\n",
    "        _, _, w, h = cv2.boundingRect(contour)\n",
    "        size = (w, h)\n",
    "\n",
    "    assert type(size) is tuple, 'Param size should be a tuple!'\n",
    "    blank = np.zeros_like(image)\n",
    "    half_x = int(size[0] * 0.5)\n",
    "    half_y = int(size[1] * 0.5)\n",
    "\n",
    "    c = get_center(contour)\n",
    "    cv2.drawContours(blank, [contour], -1, (255, 255, 255), cv2.FILLED)\n",
    "\n",
    "    return blank[c[1]-half_y:c[1]+half_y, c[0]-half_x:c[0]+half_x].copy()\n",
    "\n",
    "def resize(image, size, method=cv2.INTER_AREA):\n",
    "    ''' Resizes the image to the preffered size.  \n",
    "    Method of resizing is well suited for making the images smaller rather than larger\n",
    "    (cv2.INTER_AREA). For making images larger, use other cv2.INTER_### instead.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : numpy.ndarray\n",
    "        Contour that represents the area from image to be cropped. \n",
    "    size : tuple\n",
    "        New size of the resized image. \n",
    "    method : int\n",
    "        Optional argument. For more information see cv2.INTER_### parameters.\n",
    "    Returns\n",
    "    -------\n",
    "    Output resized image.\n",
    "    '''\n",
    "    assert type(size) is tuple, 'Variable size is NOT a tuple!'\n",
    "    return cv2.resize(image, size, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     12
    ]
   },
   "outputs": [],
   "source": [
    "def rotated_rectangle(image, idx):\n",
    "    ''' Draws rotated rectangle into the image from indexes of binary image. \n",
    "    You can get the indexes of objects from binary image using cv2.findNonZero().\n",
    "    Input image is not modified.\n",
    "    '''\n",
    "    res = image.copy()\n",
    "    rect = cv2.minAreaRect(idx)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    cv2.drawContours(res, [box], -1, (255, 255, 255), 1)\n",
    "    return res, rect\n",
    "\n",
    "def get_center(contour):\n",
    "    ''' Gets the center of contour in pixels in tuple format.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    contour : numpy.ndarray\n",
    "        input contour.\n",
    "    Returns\n",
    "    -------\n",
    "    Center in pixels in tuple format.\n",
    "    '''\n",
    "    M = cv2.moments(contour)\n",
    "    cX = int(M['m10'] / M['m00'])\n",
    "    cY = int(M['m01'] / M['m00'])\n",
    "    \n",
    "    return (cX, cY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='segmentation_functions'>Metody segmentace.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     16,
     30,
     47,
     69
    ]
   },
   "outputs": [],
   "source": [
    "def segmentation_one_threshold(img, threshold):\n",
    "    '''Segments image into black & white using one threshold\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    threshold : int\n",
    "        Pixels with value lower than threshold are considered black, the others white.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    _, dst = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY)\n",
    "    return dst\n",
    "\n",
    "def segmentation_auto_threshold(img):\n",
    "    '''Segments image into black & white using automatic threshold\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    _, dst = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    return dst\n",
    "\n",
    "def segmentation_two_thresholds(img, lower, higher):\n",
    "    '''Segments image into black & white using two thresholds\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    lower : int\n",
    "        Pixels with value lower than threshold are considered black, the others white.\n",
    "    higher : int\n",
    "        Pixels with value higher than threshold are considered black, the others white.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    return cv2.inRange(img, min(lower, higher), max(lower, higher))\n",
    "\n",
    "def segmentation_adaptive_threshold(img, size, constant=0):\n",
    "    '''Segments image into black & white using calculated adaptive \n",
    "    threshold using Gaussian function in pixel neighbourhood.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    size : int\n",
    "        Size of used gaussian. Lowest value is 3. Algorithm uses only odd numbers.\n",
    "    constant : int\n",
    "        Value that is added to calculated threshlod. It could be negative as well as zero as well as positive number.\n",
    "    Returns\n",
    "    -------\n",
    "    Output binary image.\n",
    "    '''\n",
    "    if size < 3:\n",
    "        size = 3\n",
    "    elif size % 2 == 0:\n",
    "        size -= 1\n",
    "    return cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, size, int(constant))\n",
    "\n",
    "def mask(img, mask_bin):\n",
    "    '''Masks colored image with binary mask. Output image is just logical AND between two images.'''\n",
    "    return cv2.bitwise_and(img, img, mask = mask_bin)\n",
    "\n",
    "def find_contours(img_bin, min_area=0, max_area=1000000, fill=True):\n",
    "    '''Finds contours in binary image and filters them using their area. Then it draws binary image\n",
    "    from filtered contours. It counts contours as well.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_bin : numpy.ndarray\n",
    "        Input binary image.\n",
    "    min_area : int\n",
    "        Size of contour that is used to filter all smaller contours out.\n",
    "    max_area : int\n",
    "        Size of contour that is used to filter all larger contours out.\n",
    "    Returns\n",
    "    -------\n",
    "    contour_drawn : numpy.ndarray\n",
    "        Output binary image with drawn filled filtered contours.\n",
    "    count : int\n",
    "        Number of found and filtered contours.\n",
    "    contours : list\n",
    "        Found contours.\n",
    "    '''\n",
    "    contours, _  = cv2.findContours(img_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours =  [c for c in contours if cv2.contourArea(c) > min_area and cv2.contourArea(c) < max_area]\n",
    "    thick = cv2.FILLED\n",
    "    if not fill: thick = 2\n",
    "    contour_drawn = cv2.drawContours(np.zeros(img_bin.shape, dtype=np.uint8), contours, -1, color=(255, 255, 255), thickness=thick)\n",
    "    return contour_drawn, len(contours), contours    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='filtration_functions'>Metody filtrace.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     15,
     30,
     45
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def filtration_box(img, filter_size):\n",
    "    '''Filters image noise using box blur algorithm\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    filter_size : int\n",
    "        Size of box blur filter.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    return cv2.blur(img, (filter_size, filter_size))\n",
    "\n",
    "def filtration_median(img, filter_size):\n",
    "    '''Filters image noise using median algorithm\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    filter_size : int\n",
    "        Size of median filter.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    return cv2.medianBlur(img, filter_size)   \n",
    "\n",
    "def filtration_gauss(img, filter_size, sigma_x):\n",
    "    '''Filters image noise using Gaussian blur algorithm\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : numpy.ndarray\n",
    "        Input image.\n",
    "    filter_size : int\n",
    "        Size of Gaussian filter.\n",
    "    Returns\n",
    "    -------\n",
    "    Output image.\n",
    "    '''\n",
    "    return cv2.GaussianBlur(img, (filter_size, filter_size), sigma_x) \n",
    "\n",
    "def fill_holes(img_bin, close=False, size=5):\n",
    "    '''Fill holes in found contours. It could merge the contour using close input with appropriate size.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_bin : numpy.ndarray\n",
    "        Input binary image.\n",
    "    close : boolean\n",
    "        If it should merge contours with missing points using close operation.\n",
    "    size : int\n",
    "        Size of close operation element.\n",
    "    Returns\n",
    "    -------\n",
    "    Output binary image.\n",
    "    '''\n",
    "    if close:\n",
    "        struct = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (size, size))\n",
    "        img_bin = cv2.morphologyEx(img_bin, cv2.MORPH_CLOSE, struct)\n",
    "    res, _, _ = find_contours(img_bin)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='show_functions'>Metoda pro zobrazení různého množství obrázků.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     39
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def show_images(*imgs, scale=1, window_name='Image preview'):\n",
    "    \"\"\" Opens multiple image previews depending on the length of the input *imgs list.\n",
    "    The preview is terminated by pressing the 'q' key.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    *imgs : list\n",
    "        Multiple input images which have to be shown.\n",
    "    scale : double\n",
    "        Scale of shown image window.\n",
    "    window_name : Optional[string]\n",
    "        An optional window name.\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    def print_xy(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONUP:\n",
    "            print('x = %d, y = %d'% (x, y)) \n",
    "            \n",
    "    for i, img in enumerate(imgs, 1):\n",
    "        h,w = img.shape[:2]\n",
    "        window_name_id = window_name + ' ' + str(i)\n",
    "        cv2.namedWindow(window_name_id, cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)\n",
    "        cv2.resizeWindow(window_name_id, int(w * scale), int(h * scale))\n",
    "        cv2.setMouseCallback(window_name_id, print_xy)\n",
    "        cv2.moveWindow(window_name_id, (i-1)*int(w * scale), 0)\n",
    "\n",
    "    while 1:\n",
    "        for i, img in enumerate(imgs, 1):\n",
    "            cv2.imshow(window_name + ' ' + str(i), img)\n",
    "            \n",
    "        k = cv2.waitKey(0)\n",
    "        \n",
    "        if k == ord('q') or k == 27:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def plot_images(*imgs):\n",
    "    f = plt.figure(figsize=(30, 20))\n",
    "    width = math.ceil(math.sqrt(len(imgs)))\n",
    "    height = math.ceil(len(imgs) / width)\n",
    "    for i, img in enumerate(imgs, 1):\n",
    "        ax = f.add_subplot(height, width, i)\n",
    "        ax.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ocr'>Metoda pro OCR obrazu</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def ocr(img_bin):\n",
    "    '''Detects text in the file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_bin : numpy.ndarray\n",
    "        Input binary image. White objects on black background.\n",
    "    Returns\n",
    "    -------\n",
    "    Text on image.\n",
    "    '''\n",
    "    # Tesseract works with black objects on white background.\n",
    "    img_bin = negative(img_bin)\n",
    "    return pytesseract.image_to_string(Image.fromarray(img_bin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='others'>Metody ostatní</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     13,
     18,
     26,
     29
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def to_intensity(hue_angle):\n",
    "    '''Converts color angle in HUE definition into intensity value of brightness image in opencv.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hue_angle : int\n",
    "        Angle in HUE definition.\n",
    "    Returns\n",
    "    -------\n",
    "    Integer value that represents the same HUE value but in opencv brightness image.\n",
    "    '''\n",
    "    return int(hue_angle * 0.5)\n",
    "\n",
    "def to_angle(hue_intensity):\n",
    "    '''Converts hue intensity value of brightness image in opencv into hue angle in HUE definition.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hue_intensity : int\n",
    "        Intensity value of brightness image.\n",
    "    Returns\n",
    "    -------\n",
    "    Integer value that represents the HUE angle.\n",
    "    '''\n",
    "    return hue_intensity * 2\n",
    "\n",
    "def logical_and(bin_im, bin_mask):\n",
    "    return cv2.bitwise_and(bin_im, bin_mask)\n",
    "\n",
    "def order_points(pts):\n",
    "    '''Sorts the points based on their x-coordinates.'''\n",
    "    xSorted = pts[np.argsort(pts[:, 0]), :]\n",
    "\n",
    "    # grab the left-most and right-most points from the sorted\n",
    "    # x-roodinate points\n",
    "    leftMost = xSorted[:2, :]\n",
    "    rightMost = xSorted[2:, :]\n",
    "\n",
    "    # now, sort the left-most coordinates according to their\n",
    "    # y-coordinates so we can grab the top-left and bottom-left\n",
    "    # points, respectively\n",
    "    leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
    "    (bl, tl) = leftMost\n",
    "\n",
    "    # now that we have the top-left coordinate, use it as an\n",
    "    # anchor to calculate the Euclidean distance between the\n",
    "    # top-left and right-most points; by the Pythagorean\n",
    "    # theorem, the point with the largest distance will be\n",
    "    # our bottom-right point\n",
    "    rightMost = rightMost[np.argsort(rightMost[:, 1]), :]\n",
    "    (br, tr) = rightMost\n",
    "\n",
    "    # return the coordinates in top-left, top-right,\n",
    "    # bottom-right, and bottom-left order\n",
    "    return np.array([tl, tr, br, bl], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cart_polar_functions'>Metody transformací</a>. Například převodu mezi kartézskými a polárními souřadnicemi nebo rotace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Linear polar warp help function\n",
    "def polar_warp(img, full_radius=True, inverse=False):\n",
    "    center = (img.shape[0]/2.0, img.shape[1]/2.0)\n",
    "    \n",
    "    if full_radius:\n",
    "        radius = np.sqrt(((img.shape[0]/2.0)**2.0)+((img.shape[1]/2.0)**2.0))\n",
    "    else:\n",
    "        radius = center[0]\n",
    "    \n",
    "    method = cv2.WARP_FILL_OUTLIERS\n",
    "    if inverse: \n",
    "        method += cv2.WARP_INVERSE_MAP\n",
    "    dest = cv2.linearPolar(img, center, radius, method)\n",
    "    return dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     3,
     6
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def warp_to_cartesian(img, full_radius=True):\n",
    "    return polar_warp(img, full_radius)\n",
    "\n",
    "def warp_to_polar(img, full_radius=True):\n",
    "    return polar_warp(img, full_radius, True)\n",
    "\n",
    "def rotate(img, angle):\n",
    "    height, width = img.shape[:2]\n",
    "    image_center = (width/2, height/2)\n",
    "\n",
    "    rotation_mat = cv2.getRotationMatrix2D(image_center, angle, 1.)\n",
    "\n",
    "    abs_cos = abs(rotation_mat[0,0])\n",
    "    abs_sin = abs(rotation_mat[0,1])\n",
    "\n",
    "    bound_w = int(height * abs_sin + width * abs_cos)\n",
    "    bound_h = int(height * abs_cos + width * abs_sin)\n",
    "\n",
    "    rotation_mat[0, 2] += bound_w/2 - image_center[0]\n",
    "    rotation_mat[1, 2] += bound_h/2 - image_center[1]\n",
    "\n",
    "    dest = cv2.warpAffine(img, rotation_mat, (bound_w, bound_h))\n",
    "    return dest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='artificial_funtions'>Metody na tvorbu umělých obrázků</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def artificial_circle_image(size):\n",
    "    img_art_circ = np.ndarray((size, size), dtype=np.float32)\n",
    "    step = 10\n",
    "    for i in range(step, size, step):\n",
    "        cv2.circle(img_art_circ, (int(size/2.0), int(size/2.0)), i-step, np.random.randint(0,255), thickness=4)\n",
    "    return img_art_circ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='shape_desc_funtions'>Třída pro práci s popisnými charakteristikami tvarů a jednotlivé dílčí funkce.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     24,
     29,
     38,
     46,
     56,
     66,
     75
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Dimensionless descriptors\n",
    "class ShapeDescriptors:\n",
    "    def form_factor(area, perimeter):\n",
    "        return (4 * np.pi * area) / (perimeter * perimeter)\n",
    "    \n",
    "    def roundness(area, max_diameter):\n",
    "        return (4 * area) / (np.pi * max_diameter * max_diameter)\n",
    "    \n",
    "    def aspect_ratio(min_diameter, max_diameter):\n",
    "        return min_diameter / max_diameter;\n",
    "    \n",
    "    def convexity(perimeter, convex_perimeter):\n",
    "        return convex_perimeter / perimeter\n",
    "    \n",
    "    def solidity(area, convex_area):\n",
    "        return area / convex_area\n",
    "    \n",
    "    def compactness(area, max_diameter):\n",
    "        return np.sqrt(4 / np.pi * area) / max_diameter;\n",
    "        \n",
    "    def extent(area, bounding_rectangle_area):\n",
    "        return area / bounding_rectangle_area;\n",
    "\n",
    "# Špičatost\n",
    "def form_factor(bin_im):\n",
    "    _, _, conts = find_contours(bin_im)\n",
    "    return ShapeDescriptors.form_factor(cv2.contourArea(conts[0]), cv2.arcLength(conts[0], True))\n",
    "\n",
    "# Kulatost\n",
    "def roundness(bin_im):\n",
    "    _, _, conts = find_contours(bin_im)\n",
    "    area = cv2.contourArea(conts[0])\n",
    "    _,radius = cv2.minEnclosingCircle(conts[0])\n",
    "    r = ShapeDescriptors.roundness(area, 2*radius)\n",
    "    if r > 1: r = 1\n",
    "    return r\n",
    "\n",
    "# Poměr stran\n",
    "def aspect_ratio(bin_im):\n",
    "    _, _, conts = find_contours(bin_im)\n",
    "    dims = cv2.minAreaRect(conts[0])[1]\n",
    "    min_diameter = min(dims)\n",
    "    max_diameter = max(dims)\n",
    "    return ShapeDescriptors.aspect_ratio(min_diameter, max_diameter)\n",
    "    \n",
    "# Konvexita, vypouklost\n",
    "def convexity(bin_im):\n",
    "    _, _, conts = find_contours(bin_im)\n",
    "    hull = cv2.convexHull(conts[0], None, True, True)\n",
    "    per = cv2.arcLength(conts[0], True)\n",
    "    conv_per = cv2.arcLength(hull, True)\n",
    "    r = ShapeDescriptors.convexity(per, conv_per)\n",
    "    if r > 1: r = 1\n",
    "    return r \n",
    "\n",
    "# Plnost, celistvost\n",
    "def solidity(bin_im):\n",
    "    _, _, conts = find_contours(bin_im)\n",
    "    hull = cv2.convexHull(conts[0], None, True, True)\n",
    "    area = cv2.contourArea(conts[0])\n",
    "    conv_area = cv2.contourArea(hull)\n",
    "    r = ShapeDescriptors.solidity(area, conv_area)\n",
    "    if r > 1: r = 1\n",
    "    return r \n",
    "    \n",
    "# Kompaktnost, hutnost\n",
    "def compactness(bin_im):\n",
    "    _, _, conts = find_contours(bin_im)\n",
    "    area = cv2.contourArea(conts[0])\n",
    "    max_diameter = max(cv2.minAreaRect(conts[0])[1])\n",
    "    r = ShapeDescriptors.compactness(area, max_diameter)\n",
    "    if r > 1: r = 1\n",
    "    return r \n",
    "    \n",
    "# Dosah, rozměrnost\n",
    "def extent(bin_im):\n",
    "    _, _, conts = find_contours(bin_im)\n",
    "    area = cv2.contourArea(conts[0])\n",
    "    w, h = cv2.minAreaRect(conts[0])[1]\n",
    "    return ShapeDescriptors.extent(area, w*h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='measuring_funtions'>Metody pro práci při segmentaci a měření objektů</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     7,
     11,
     38,
     61,
     74
    ]
   },
   "outputs": [],
   "source": [
    "def copy_to(src, dst, mask):\n",
    "    '''Python alternative to C++/Java OpenCV's Mat.copyTo().\n",
    "    More: https://docs.opencv.org/trunk/d3/d63/classcv_1_1Mat.html#a626fe5f96d02525e2604d2ad46dd574f'''\n",
    "    locs = np.where(mask != 0) # Get the non-zero mask locations\n",
    "    dst[locs[0], locs[1]] = src[locs[0], locs[1]]\n",
    "    return dst\n",
    "\n",
    "def midpoint(ptA, ptB):\n",
    "    '''Returns the midpoint between two input points.'''\n",
    "    return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n",
    "\n",
    "def order_points(pts):\n",
    "    '''Sorts the points based on their x-coordinates.'''\n",
    "    xSorted = pts[np.argsort(pts[:, 0]), :]\n",
    "\n",
    "    # grab the left-most and right-most points from the sorted\n",
    "    # x-roodinate points\n",
    "    leftMost = xSorted[:2, :]\n",
    "    rightMost = xSorted[2:, :]\n",
    "\n",
    "    # now, sort the left-most coordinates according to their\n",
    "    # y-coordinates so we can grab the top-left and bottom-left\n",
    "    # points, respectively\n",
    "    leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
    "    (bl, tl) = leftMost\n",
    "\n",
    "    # now that we have the top-left coordinate, use it as an\n",
    "    # anchor to calculate the Euclidean distance between the\n",
    "    # top-left and right-most points; by the Pythagorean\n",
    "    # theorem, the point with the largest distance will be\n",
    "    # our bottom-right point\n",
    "    rightMost = rightMost[np.argsort(rightMost[:, 1]), :]\n",
    "    (br, tr) = rightMost\n",
    "\n",
    "    # return the coordinates in top-left, top-right,\n",
    "    # bottom-right, and bottom-left order\n",
    "    return np.array([tl, tr, br, bl], dtype=\"float32\")\n",
    "\n",
    "def rotate_image(image, angle, image_center=None):\n",
    "    \"\"\" Rotates the input image by specified angle.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        Image to be rotated.\n",
    "    angle : float\n",
    "        Rotation angle.\n",
    "    image_center : Optional[tuple(int, int)]\n",
    "        Center of rotation.\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Returns the rotated input image by specified angle.\n",
    "    \"\"\"\n",
    "    if image_center is None:\n",
    "        image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result\n",
    "\n",
    "# TODO: Most inefficient function in my whole life \n",
    "def draw_rotated_text(img, text, point, angle, text_scale, text_color, text_thickness):\n",
    "    img_filled = np.full(img.shape, text_color, dtype=np.uint8)\n",
    "    # create rotated text mask\n",
    "    text_mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
    "    cv2.putText(text_mask, \"{:.2f} cm\".format(text), point, 0, text_scale, (255, 255, 255), text_thickness)\n",
    "    if angle > 0:\n",
    "        angle = -angle + 90\n",
    "    elif angle < 0:\n",
    "        angle = angle + 90\n",
    "    text_mask = rotate_image(text_mask, -angle, point)\n",
    "    result = copy_to(img_filled, img.copy(), text_mask)\n",
    "    return result\n",
    "\n",
    "def draw_real_sizes(img, rect, width_text, height_text, lbl_size_scale=2, lbl_color=(0, 0, 255), lbl_thickness=8):\n",
    "    tl, tr, br, bl = order_points(cv2.boxPoints(rect))\n",
    "    mid_pt_width = midpoint(tl, tr)\n",
    "    mid_pt_height = midpoint(tr, br)\n",
    "    \n",
    "    # bottom-left points where labels are drawn\n",
    "    pt_label_first =  (int(mid_pt_width[0] - 10), int(mid_pt_width[1] - 10))\n",
    "    pt_label_second = (int(mid_pt_height[0] + 10), int(mid_pt_height[1]))\n",
    "        \n",
    "    result = draw_rotated_text(img, width_text, pt_label_first, rect[2], lbl_size_scale, lbl_color, lbl_thickness)\n",
    "    result = draw_rotated_text(result, height_text, pt_label_second, rect[2], lbl_size_scale, lbl_color, lbl_thickness)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Kalibrace kamery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load_save_functions'>Funkce sloužící k načítaní/ukládání kalibrace ze souboru.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     24
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "IDX_CAM_MATRIX = \"camera_matrix\"\n",
    "IDX_DIST_COEFFS = \"dist_coefs\"\n",
    "\n",
    "def load_camera_calib(input_file):\n",
    "    \"\"\" Loads camera calibration from specified input file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_file : string\n",
    "        Input file with calibration data in YAML format.\n",
    "    Returns\n",
    "    -------\n",
    "    tuple(np.array, np.array)\n",
    "        Returns a tuple where first element is camera matrix array and second element is dist coefficients array. \n",
    "        These arrays might be empty if the file isn't found or in correct format.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(input_file, 'r') as stream:\n",
    "            data = yaml.load(stream)\n",
    "            return data[IDX_CAM_MATRIX], data[IDX_DIST_COEFFS]\n",
    "    except (FileNotFoundError, yaml.YAMLError) as exc:\n",
    "        print(f'File {input_file} couldn\\'t be read.')\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "def save_camera_calib(output_file, camera_matrix, dist_coefs):\n",
    "    \"\"\" Saves camera calibration to specified output file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    output_file : string\n",
    "        Output file used for storing calibration data in YAML format. Parent directory is created if needed.\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    data = {IDX_CAM_MATRIX: camera_matrix, IDX_DIST_COEFFS: dist_coefs}\n",
    "    output_dir = os.path.dirname(output_file)\n",
    "    \n",
    "    if not os.path.isdir(output_dir):\n",
    "            os.mkdir(output_dir)\n",
    "            \n",
    "    with open(output_file, \"w\") as f:\n",
    "        yaml.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='correct_functions'>Funkce k opravě obrázku pomocí získaných kalibračních dat.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def correct_frame(frame, camera_matrix, dist_coeffs):\n",
    "    \"\"\"Returns undistorted frame.\"\"\"\n",
    "    return cv2.undistort(frame, camera_matrix, dist_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reindex_functions'>Funkce sloužící k přejmenování souborů ve složce</a>, aby je bylo možné snadně použít v cv2.VideoCapture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:33:19.348616Z",
     "start_time": "2019-07-15T11:33:19.340639Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def reindex_image_files(source_dir, output_dir=None):\n",
    "    \"\"\" Reads all images in source_dir and based on they original order, \n",
    "    change their filename to be continuous integer (starting from 0). \n",
    "    Then, they can be easily read by cv2.VideoCapture. Image format is kept.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    source_dir : string\n",
    "        Input images directory that have to be renamed.\n",
    "    output_dir : Optional[string]\n",
    "        Output directory for renamed files. If not specified, renaming is done inplace in source_dir.\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    input_files = []\n",
    "    \n",
    "    for file in os.listdir(source_dir):\n",
    "        if re.match(r'.*(\\.bmp|\\.jpg|\\.png|\\.gif)$', file, re.I):\n",
    "            input_files.append(os.path.join(source_dir, file))\n",
    "\n",
    "    if not input_files:\n",
    "        print('No files were found.')\n",
    "        return\n",
    "    \n",
    "    extension = '.' + input_files[0].split(\".\")[-1]\n",
    "    if output_dir is None:\n",
    "        for i, filename in enumerate(natsorted(input_files)):\n",
    "            os.rename(filename, os.path.join(source_dir, str(i) +  extension))\n",
    "        print(f'Files within {source_dir} were renamed, starting from 0{extension} to {i}{extension}.')\n",
    "    else:\n",
    "        if not os.path.isdir(output_dir):\n",
    "            os.mkdir(output_dir)\n",
    "\n",
    "        for i, filename in enumerate(natsorted(input_files)):\n",
    "            shutil.copy(filename, os.path.join(output_dir, str(i) + extension))\n",
    "            \n",
    "        print(f'Files from {source_dir} were renamed and saved to {output_dir}, starting from 0{extension} to {i}{extension}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pick_functions'>Funkce k rychlému výběru chtěných snímků z obrazového zdroje.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def pick_frames(input_source, output_dir, wait_time):\n",
    "    \"\"\" Sequentially shows all images from input_source. \n",
    "    Using 'p' key allows to pick wanted frames and save them in separate folder (output_dir).\n",
    "    The preview is terminated by pressing the 'q' key.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_source : string\n",
    "        Input source for cv2.VideoCapture (could be camera source or sequence of saved images where format has to be specified).\n",
    "    output_dir : string\n",
    "        Output directory for picked files. Automatically created if needed.\n",
    "    wait_time : int\n",
    "        Delay in ms between shown images.\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    window_name = 'Frame preview'\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(window_name, CAM_WIDTH, CAM_HEIGHT)\n",
    "    cv2.moveWindow(window_name, 0, 0)\n",
    "    \n",
    "    cap = cv2.VideoCapture(input_source)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        cv2.destroyAllWindows()\n",
    "        raise FileNotFoundError('Capture cannot be opened.')\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    \n",
    "    saved_counter = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: \n",
    "            break\n",
    "            \n",
    "        cv2.imshow(window_name, frame)\n",
    "        k = cv2.waitKey(wait_time) & 0xFF\n",
    "    \n",
    "        if k == ord('p'):\n",
    "            img_format = input_source.split('.')[-1] if '.' in input_source else 'jpg'\n",
    "            cv2.imwrite(os.path.join(output_dir, str(saved_counter) + '.' + img_format), frame)\n",
    "            saved_counter += 1\n",
    "        elif k == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f'{saved_counter} frames saved to {output_dir}')          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='calib_functions'>Funkce provádějící kalibraci kamery</a>, kterou je možné uložit k pozdějšímu využití."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:34:36.169410Z",
     "start_time": "2019-07-15T11:34:36.164424Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def camera_calib(input_source, chess_shape, output_calib_file=None, img_show_delay=1):\n",
    "    \"\"\" Browses all images found in input_source and on each image tries to find chessboard corners.\n",
    "    If chessboard corners are found, image corespondences with real world space are added to lists.\n",
    "    Based on these image-world corespondences, camera calibration is made.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_source : string\n",
    "        Input source for cv2.VideoCapture (could be camera source or sequence of saved images where format has to be specified).\n",
    "    chess_shape : tuple\n",
    "        Number of inner corners per a chessboard row and column.\n",
    "    output_calib_file : Optional[string]\n",
    "        Output file where calibration is saved when neccesary.\n",
    "    img_show_delay : int\n",
    "        Delay in ms between shown images.\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        camera matrix and distance coefficients\n",
    "    \"\"\"\n",
    "    window_name = 'Frame preview'\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(window_name, CAM_WIDTH, CAM_HEIGHT)\n",
    "    cv2.moveWindow(window_name, 0, 0)\n",
    "\n",
    "    cap = cv2.VideoCapture(input_source)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        cv2.destroyAllWindows()\n",
    "        raise FileNotFoundError('Capture cannot be opened.')\n",
    "\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((chess_shape[0] * chess_shape[1], 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:chess_shape[0], 0:chess_shape[1]].T.reshape(-1, 2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = []  # 3d point in real world space\n",
    "    imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, chess_shape)\n",
    "\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret:\n",
    "            objpoints.append(objp)\n",
    "            corners = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.1))\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            frame = cv2.drawChessboardCorners(frame, chess_shape, corners, ret)\n",
    "\n",
    "        cv2.imshow(window_name, frame)\n",
    "\n",
    "        k = cv2.waitKey(img_show_delay) & 0xFF\n",
    "        if k == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print('Computing camera matrix...')\n",
    "    rms, camera_matrix, dist_coefs, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    \n",
    "    if output_calib_file is not None:\n",
    "        save_camera_calib(output_calib_file, camera_matrix, dist_coefs)\n",
    "\n",
    "    print('\\nRMS:', rms)\n",
    "    print('Camera matrix:\\n', camera_matrix)\n",
    "    print('Distortion coefficients: ', dist_coefs.ravel())\n",
    "    \n",
    "    return camera_matrix, dist_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='path_functions'>Funkce pro vytvoření cesty z názvů složek a názvů souboru.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T13:37:04.896509Z",
     "start_time": "2019-07-15T13:37:04.885021Z"
    },
    "code_folding": [
     0,
     24
    ]
   },
   "outputs": [],
   "source": [
    "def create_folder_path(base_folder, new_folder_name):\n",
    "    \"\"\" Creates all neccessary folders in the folder tree structure on computer. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    base_folder : string\n",
    "        Base folder directory in string notation. \n",
    "    output_dir : string\n",
    "        Folder name that should be inside the base folder.\n",
    "    Returns\n",
    "    -------\n",
    "    string\n",
    "        Path to the newly created folder.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(base_folder):\n",
    "        os.mkdir(base_folder)\n",
    "            \n",
    "    path = os.path.join(base_folder, new_folder_name)        \n",
    "    \n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)      \n",
    "            \n",
    "    return path\n",
    "\n",
    "def create_file_path(folder, file_name):\n",
    "    '''Easier defined function to create path for filename inside a folder.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    folder : string\n",
    "        Base folder directory in string notation. \n",
    "    file_name : string\n",
    "        File name that should be inside the base folder.\n",
    "    Returns\n",
    "    -------\n",
    "    string\n",
    "        Path to the newly created file.\n",
    "    \"\"\"\n",
    "    '''\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)\n",
    "        \n",
    "    return os.path.join(folder, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Odhad výšky\n",
    "<a id='height_estimation_functions'>Hotové funkce a modely pro výpočty.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1,
     12,
     23,
     34,
     45
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Funkce pro konverze mezi typy souřadnic\n",
    "def convert_pt_to_homogenous(pt):\n",
    "    \"\"\"\n",
    "    Convert input point in inhomogeneous coordinates to homogeneous.\n",
    "\n",
    "    :param pt: ndarray\n",
    "        Input point in inhomogeneous coordinates.\n",
    "    :return: ndarray\n",
    "        Input point in homogeneous coordinates.\n",
    "    \"\"\"\n",
    "    return np.append(pt, np.array(1))\n",
    "\n",
    "def convert_pt_from_homogenous(pt):\n",
    "    \"\"\"\n",
    "    Convert input point in homogeneous coordinates to inhomogeneous.\n",
    "\n",
    "    :param pt: ndarray\n",
    "        Input point in homogeneous coordinates.\n",
    "    :return: ndarray\n",
    "        Input point in inhomogeneous coordinates.\n",
    "    \"\"\"\n",
    "    return tuple([elem / pt[-1] for elem in pt[:-1]])\n",
    "\n",
    "def convert_pts_to_homogenous(pts):\n",
    "    \"\"\"\n",
    "    Convert input points in inhomogeneous coordinates to homogeneous.\n",
    "\n",
    "    :param pt: ndarray\n",
    "        Input points in inhomogeneous coordinates.\n",
    "    :return: ndarray\n",
    "        Input points in homogeneous coordinates.\n",
    "    \"\"\"\n",
    "    return np.array([convert_pt_to_homogenous(pt) for pt in pts])\n",
    "\n",
    "def convert_pts_from_homogenous(pts):\n",
    "    \"\"\"\n",
    "    Convert input points in homogeneous coordinates to inhomogeneous.\n",
    "\n",
    "    :param pt: ndarray\n",
    "        Input points in homogeneous coordinates.\n",
    "    :return: ndarray\n",
    "        Input points in inhomogeneous coordinates.\n",
    "    \"\"\"\n",
    "    return np.array([convert_pt_from_homogenous(pt) for pt in pts])\n",
    "\n",
    "def _calc_alfa_metric_factor(ref_measurements, vanish_line, vert_vanish_point):\n",
    "    \"\"\" Calculates alfa metric factor using multiple reference measurements via minimization ||As|| = 0. This is done by SVD.\n",
    "        In depth overview can be found in https://www.robots.ox.ac.uk/~vgg/publications/1999/Criminisi99b/criminisi99b.pdf - PDF page 104.\n",
    "\n",
    "    :param ref_measurements: list\n",
    "        Each measurement is in (t_ref, b_ref, height) format. Image coordinates are in inhomogeneous format.\n",
    "    :param vanish_line: ndarray\n",
    "        Homogenous coordinates of vanishing line.\n",
    "    :param vert_vanish_point: ndarray\n",
    "        Homogenous coordinates of vanishing point in reference direction.\n",
    "    :return: float\n",
    "        Scalar value of alfa metric factor calculated by SVD.\n",
    "    \"\"\"\n",
    "    matrix_A = np.empty((len(ref_measurements), 2), dtype='float64')\n",
    "\n",
    "    for i, (t_ref, b_ref, h_ref) in enumerate(ref_measurements):\n",
    "        t_ref = convert_pt_to_homogenous(t_ref)\n",
    "        b_ref = convert_pt_to_homogenous(b_ref)\n",
    "        beta = np.linalg.norm(np.cross(b_ref, t_ref))\n",
    "        ro = np.dot(vanish_line, b_ref)\n",
    "        gamma = np.linalg.norm(np.cross(vert_vanish_point, t_ref))\n",
    "        matrix_A[i] = (h_ref * ro * gamma, beta)\n",
    "        # alfa_metric_factor = - np.linalg.norm(np.cross(b_ref, t_ref)) / \\\n",
    "        #                               (h_ref * (np.dot(vanish_line, b_ref)) * np.linalg.norm(np.cross(vert_vanish_point, t_ref)))\n",
    "        # print(alfa_metric_factor)\n",
    "\n",
    "    u, s, vh = np.linalg.svd(matrix_A)\n",
    "    return vh[0, -1] / vh[1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Třída pro počítání odhadu výšky\n",
    "class HeightEstimator:\n",
    "    \n",
    "    def __init__(self, ref_measurements, vl, vz):\n",
    "        self._vanish_line = vl\n",
    "        self._vert_vanish_point = vz\n",
    "        self._alfa_metric_factor = _calc_alfa_metric_factor(ref_measurements, self._vanish_line, self._vert_vanish_point)\n",
    "\n",
    "    def calc_height(self, top_point, bottom_point):\n",
    "        \"\"\"\n",
    "        Calculates real world height based on top_point and bottom_point measured on image plane.\n",
    "\n",
    "        :param top_point: ndarray\n",
    "            Top point in reference direction of the object in inhomogeneous format.\n",
    "        :param bottom_point: ndarray\n",
    "            Ground plane point of the object in inhomogeneous format.\n",
    "        :return: float\n",
    "            Scalar value representing real world height.\n",
    "        \"\"\"\n",
    "        top_point = convert_pt_to_homogenous(top_point)\n",
    "        bottom_point = convert_pt_to_homogenous(bottom_point)\n",
    "        # This formula comes from paper Single view metrology by A. Criminisi.\n",
    "        height = - np.linalg.norm(np.cross(bottom_point, top_point)) / (\n",
    "                self._alfa_metric_factor * (np.dot(self._vanish_line, bottom_point)) * np.linalg.norm(np.cross(self._vert_vanish_point, top_point)))\n",
    "        return height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     11,
     59,
     81,
     121,
     179,
     215,
     242,
     343,
     360,
     380
    ]
   },
   "outputs": [],
   "source": [
    "# Algoritmus automatizovaného výpočtu úběžníků a úběžnic v obraze\n",
    "\"\"\"\n",
    "References\n",
    "----------\n",
    "1.  Chaudhury, Krishnendu, Stephen DiVerdi, and Sergey Ioffe.\n",
    "    \"Auto-rectification of user photos.\" 2014 IEEE International Conference on\n",
    "    Image Processing (ICIP). IEEE, 2014.\n",
    "2.  Bazin, Jean-Charles, and Marc Pollefeys. \"3-line RANSAC for orthogonal\n",
    "    vanishing point detection.\" 2012 IEEE/RSJ International Conference on\n",
    "    Intelligent Robots and Systems. IEEE, 2012.\n",
    "\"\"\"\n",
    "def compute_edgelets(image, sigma=3):\n",
    "    \"\"\"Create edgelets as in the paper.\n",
    "\n",
    "    Uses canny edge detection and then finds (small) lines using probabilstic\n",
    "    hough transform as edgelets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: ndarray\n",
    "        Image for which edgelets are to be computed.\n",
    "    sigma: float\n",
    "        Smoothing to be used for canny edge detection.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    locations: ndarray of shape (n_edgelets, 2)\n",
    "        Locations of each of the edgelets.\n",
    "    directions: ndarray of shape (n_edgelets, 2)\n",
    "        Direction of the edge (tangent) at each of the edgelet.\n",
    "    strengths: ndarray of shape (n_edgelets,)\n",
    "        Length of the line segments detected for the edgelet.\n",
    "    \"\"\"\n",
    "    gray_img = color.rgb2gray(image)\n",
    "    edges = feature.canny(gray_img, sigma)\n",
    "    lines = transform.probabilistic_hough_line(edges, line_length=3,\n",
    "                                               line_gap=2)\n",
    "\n",
    "    locations = []\n",
    "    directions = []\n",
    "    strengths = []\n",
    "\n",
    "    for p0, p1 in lines:\n",
    "        p0, p1 = np.array(p0), np.array(p1)\n",
    "        locations.append((p0 + p1) / 2)\n",
    "        directions.append(p1 - p0)\n",
    "        strengths.append(np.linalg.norm(p1 - p0))\n",
    "\n",
    "    # convert to numpy arrays and normalize\n",
    "    locations = np.array(locations)\n",
    "    directions = np.array(directions)\n",
    "    strengths = np.array(strengths)\n",
    "\n",
    "    directions = np.array(directions) / \\\n",
    "        np.linalg.norm(directions, axis=1)[:, np.newaxis]\n",
    "\n",
    "    return (locations, directions, strengths)\n",
    "\n",
    "\n",
    "def edgelet_lines(edgelets):\n",
    "    \"\"\"Compute lines in homogenous system for edglets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edgelets: tuple of ndarrays\n",
    "        (locations, directions, strengths) as computed by `compute_edgelets`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lines: ndarray of shape (n_edgelets, 3)\n",
    "        Lines at each of edgelet locations in homogenous system.\n",
    "    \"\"\"\n",
    "    locations, directions, _ = edgelets\n",
    "    normals = np.zeros_like(directions)\n",
    "    normals[:, 0] = directions[:, 1]\n",
    "    normals[:, 1] = -directions[:, 0]\n",
    "    p = -np.sum(locations * normals, axis=1)\n",
    "    lines = np.concatenate((normals, p[:, np.newaxis]), axis=1)\n",
    "    return lines\n",
    "\n",
    "\n",
    "def compute_votes(edgelets, model, threshold_inlier=5):\n",
    "    \"\"\"Compute votes for each of the edgelet against a given vanishing point.\n",
    "\n",
    "    Votes for edgelets which lie inside threshold are same as their strengths,\n",
    "    otherwise zero.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edgelets: tuple of ndarrays\n",
    "        (locations, directions, strengths) as computed by `compute_edgelets`.\n",
    "    model: ndarray of shape (3,)\n",
    "        Vanishing point model in homogenous cordinate system.\n",
    "    threshold_inlier: float\n",
    "        Threshold to be used for computing inliers in degrees. Angle between\n",
    "        edgelet direction and line connecting the  Vanishing point model and\n",
    "        edgelet location is used to threshold.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    votes: ndarry of shape (n_edgelets,)\n",
    "        Votes towards vanishing point model for each of the edgelet.\n",
    "\n",
    "    \"\"\"\n",
    "    vp = model[:2] / model[2]\n",
    "\n",
    "    locations, directions, strengths = edgelets\n",
    "\n",
    "    est_directions = locations - vp\n",
    "    dot_prod = np.sum(est_directions * directions, axis=1)\n",
    "    abs_prod = np.linalg.norm(directions, axis=1) * \\\n",
    "        np.linalg.norm(est_directions, axis=1)\n",
    "    abs_prod[abs_prod == 0] = 1e-5\n",
    "\n",
    "    cosine_theta = dot_prod / abs_prod\n",
    "    theta = np.arccos(np.abs(cosine_theta))\n",
    "\n",
    "    theta_thresh = threshold_inlier * np.pi / 180\n",
    "    return (theta < theta_thresh) * strengths\n",
    "\n",
    "\n",
    "def ransac_vanishing_point(edgelets, num_ransac_iter=2000, threshold_inlier=5):\n",
    "    \"\"\"Estimate vanishing point using Ransac.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edgelets: tuple of ndarrays\n",
    "        (locations, directions, strengths) as computed by `compute_edgelets`.\n",
    "    num_ransac_iter: int\n",
    "        Number of iterations to run ransac.\n",
    "    threshold_inlier: float\n",
    "        threshold to be used for computing inliers in degrees.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_model: ndarry of shape (3,)\n",
    "        Best model for vanishing point estimated.\n",
    "\n",
    "    Reference\n",
    "    ---------\n",
    "    Chaudhury, Krishnendu, Stephen DiVerdi, and Sergey Ioffe.\n",
    "    \"Auto-rectification of user photos.\" 2014 IEEE International Conference on\n",
    "    Image Processing (ICIP). IEEE, 2014.\n",
    "    \"\"\"\n",
    "    locations, directions, strengths = edgelets\n",
    "    lines = edgelet_lines(edgelets)\n",
    "\n",
    "    num_pts = strengths.size\n",
    "\n",
    "    arg_sort = np.argsort(-strengths)\n",
    "    first_index_space = arg_sort[:num_pts // 5]\n",
    "    second_index_space = arg_sort[:num_pts // 2]\n",
    "\n",
    "    best_model = None\n",
    "    best_votes = np.zeros(num_pts)\n",
    "\n",
    "    for ransac_iter in range(num_ransac_iter):\n",
    "        ind1 = np.random.choice(first_index_space)\n",
    "        ind2 = np.random.choice(second_index_space)\n",
    "\n",
    "        l1 = lines[ind1]\n",
    "        l2 = lines[ind2]\n",
    "\n",
    "        current_model = np.cross(l1, l2)\n",
    "\n",
    "        if np.sum(current_model**2) < 1 or current_model[2] == 0:\n",
    "            # reject degenerate candidates\n",
    "            continue\n",
    "\n",
    "        current_votes = compute_votes(\n",
    "            edgelets, current_model, threshold_inlier)\n",
    "\n",
    "        if current_votes.sum() > best_votes.sum():\n",
    "            best_model = current_model\n",
    "            best_votes = current_votes\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def reestimate_model(model, edgelets, threshold_reestimate=5):\n",
    "    \"\"\"Reestimate vanishing point using inliers and least squares.\n",
    "\n",
    "    All the edgelets which are within a threshold are used to reestimate model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: ndarry of shape (3,)\n",
    "        Vanishing point model in homogenous coordinates which is to be\n",
    "        reestimated.\n",
    "    edgelets: tuple of ndarrays\n",
    "        (locations, directions, strengths) as computed by `compute_edgelets`.\n",
    "        All edgelets from which inliers will be computed.\n",
    "    threshold_inlier: float\n",
    "        threshold to be used for finding inlier edgelets.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    restimated_model: ndarry of shape (3,)\n",
    "        Reestimated model for vanishing point in homogenous coordinates.\n",
    "    \"\"\"\n",
    "    locations, directions, strengths = edgelets\n",
    "\n",
    "    inliers = compute_votes(edgelets, model, threshold_reestimate) > 0\n",
    "    locations = locations[inliers]\n",
    "    directions = directions[inliers]\n",
    "    strengths = strengths[inliers]\n",
    "\n",
    "    lines = edgelet_lines((locations, directions, strengths))\n",
    "\n",
    "    a = lines[:, :2]\n",
    "    b = -lines[:, 2]\n",
    "    est_model = np.linalg.lstsq(a, b)[0]\n",
    "    return np.concatenate((est_model, [1.]))\n",
    "\n",
    "\n",
    "def remove_inliers(model, edgelets, threshold_inlier=10):\n",
    "    \"\"\"Remove all inlier edglets of a given model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: ndarry of shape (3,)\n",
    "        Vanishing point model in homogenous coordinates which is to be\n",
    "        reestimated.\n",
    "    edgelets: tuple of ndarrays\n",
    "        (locations, directions, strengths) as computed by `compute_edgelets`.\n",
    "    threshold_inlier: float\n",
    "        threshold to be used for finding inlier edgelets.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    edgelets_new: tuple of ndarrays\n",
    "        All Edgelets except those which are inliers to model.\n",
    "    \"\"\"\n",
    "    inliers = compute_votes(edgelets, model, 10) > 0\n",
    "    locations, directions, strengths = edgelets\n",
    "    locations = locations[~inliers]\n",
    "    directions = directions[~inliers]\n",
    "    strengths = strengths[~inliers]\n",
    "    edgelets = (locations, directions, strengths)\n",
    "    return edgelets\n",
    "\n",
    "\n",
    "def compute_homography_and_warp(image, vp1, vp2, clip=True, clip_factor=3):\n",
    "    \"\"\"Compute homography from vanishing points and warp the image.\n",
    "\n",
    "    It is assumed that vp1 and vp2 correspond to horizontal and vertical\n",
    "    directions, although the order is not assumed.\n",
    "    Firstly, projective transform is computed to make the vanishing points go\n",
    "    to infinty so that we have a fronto parellel view. Then,Computes affine\n",
    "    transfom  to make axes corresponding to vanishing points orthogonal.\n",
    "    Finally, Image is translated so that the image is not missed. Note that\n",
    "    this image can be very large. `clip` is provided to deal with this.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: ndarray\n",
    "        Image which has to be wrapped.\n",
    "    vp1: ndarray of shape (3, )\n",
    "        First vanishing point in homogenous coordinate system.\n",
    "    vp2: ndarray of shape (3, )\n",
    "        Second vanishing point in homogenous coordinate system.\n",
    "    clip: bool, optional\n",
    "        If True, image is clipped to clip_factor.\n",
    "    clip_factor: float, optional\n",
    "        Proportion of image in multiples of image size to be retained if gone\n",
    "        out of bounds after homography.\n",
    "    Returns\n",
    "    -------\n",
    "    warped_img: ndarray\n",
    "        Image warped using homography as described above.\n",
    "    \"\"\"\n",
    "    # Find Projective Transform\n",
    "    vanishing_line = np.cross(vp1, vp2)\n",
    "    H = np.eye(3)\n",
    "    H[2] = vanishing_line / vanishing_line[2]\n",
    "    H = H / H[2, 2]\n",
    "\n",
    "    # Find directions corresponding to vanishing points\n",
    "    v_post1 = np.dot(H, vp1)\n",
    "    v_post2 = np.dot(H, vp2)\n",
    "    v_post1 = v_post1 / np.sqrt(v_post1[0]**2 + v_post1[1]**2)\n",
    "    v_post2 = v_post2 / np.sqrt(v_post2[0]**2 + v_post2[1]**2)\n",
    "\n",
    "    directions = np.array([[v_post1[0], -v_post1[0], v_post2[0], -v_post2[0]],\n",
    "                           [v_post1[1], -v_post1[1], v_post2[1], -v_post2[1]]])\n",
    "\n",
    "    thetas = np.arctan2(directions[0], directions[1])\n",
    "\n",
    "    # Find direction closest to horizontal axis\n",
    "    h_ind = np.argmin(np.abs(thetas))\n",
    "\n",
    "    # Find positve angle among the rest for the vertical axis\n",
    "    if h_ind // 2 == 0:\n",
    "        v_ind = 2 + np.argmax([thetas[2], thetas[3]])\n",
    "    else:\n",
    "        v_ind = np.argmax([thetas[2], thetas[3]])\n",
    "\n",
    "    A1 = np.array([[directions[0, v_ind], directions[0, h_ind], 0],\n",
    "                   [directions[1, v_ind], directions[1, h_ind], 0],\n",
    "                   [0, 0, 1]])\n",
    "    # Might be a reflection. If so, remove reflection.\n",
    "    if np.linalg.det(A1) < 0:\n",
    "        A1[:, 0] = -A1[:, 0]\n",
    "\n",
    "    A = np.linalg.inv(A1)\n",
    "\n",
    "    # Translate so that whole of the image is covered\n",
    "    inter_matrix = np.dot(A, H)\n",
    "\n",
    "    cords = np.dot(inter_matrix, [[0, 0, image.shape[1], image.shape[1]],\n",
    "                                  [0, image.shape[0], 0, image.shape[0]],\n",
    "                                  [1, 1, 1, 1]])\n",
    "    cords = cords[:2] / cords[2]\n",
    "\n",
    "    tx = min(0, cords[0].min())\n",
    "    ty = min(0, cords[1].min())\n",
    "\n",
    "    max_x = cords[0].max() - tx\n",
    "    max_y = cords[1].max() - ty\n",
    "\n",
    "    if clip:\n",
    "        # These might be too large. Clip them.\n",
    "        max_offset = max(image.shape) * clip_factor / 2\n",
    "        tx = max(tx, -max_offset)\n",
    "        ty = max(ty, -max_offset)\n",
    "\n",
    "        max_x = min(max_x, -tx + max_offset)\n",
    "        max_y = min(max_y, -ty + max_offset)\n",
    "\n",
    "    max_x = int(max_x)\n",
    "    max_y = int(max_y)\n",
    "\n",
    "    T = np.array([[1, 0, -tx],\n",
    "                  [0, 1, -ty],\n",
    "                  [0, 0, 1]])\n",
    "\n",
    "    final_homography = np.dot(T, inter_matrix)\n",
    "\n",
    "    warped_img = transform.warp(image, np.linalg.inv(final_homography),\n",
    "                                output_shape=(max_y, max_x))\n",
    "    return warped_img\n",
    "\n",
    "\n",
    "def vis_edgelets(image, edgelets, show=True):\n",
    "    \"\"\"Helper function to visualize edgelets.\"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    locations, directions, strengths = edgelets\n",
    "    for i in range(locations.shape[0]):\n",
    "        xax = [locations[i, 0] - directions[i, 0] * strengths[i] / 2,\n",
    "               locations[i, 0] + directions[i, 0] * strengths[i] / 2]\n",
    "        yax = [locations[i, 1] - directions[i, 1] * strengths[i] / 2,\n",
    "               locations[i, 1] + directions[i, 1] * strengths[i] / 2]\n",
    "\n",
    "        plt.plot(xax, yax, 'r-')\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def vis_model(image, model, show=True):\n",
    "    \"\"\"Helper function to visualize computed model.\"\"\"\n",
    "    edgelets = compute_edgelets(image)\n",
    "    locations, directions, strengths = edgelets\n",
    "    inliers = compute_votes(edgelets, model, 10) > 0\n",
    "\n",
    "    edgelets = (locations[inliers], directions[inliers], strengths[inliers])\n",
    "    locations, directions, strengths = edgelets\n",
    "    vis_edgelets(image, edgelets, False)\n",
    "    vp = model / model[2]\n",
    "    plt.plot(vp[0], vp[1], 'bo')\n",
    "    for i in range(locations.shape[0]):\n",
    "        xax = [locations[i, 0], vp[0]]\n",
    "        yax = [locations[i, 1], vp[1]]\n",
    "        plt.plot(xax, yax, 'b-.')\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def compute_vanishing_points(image, clip_factor=6, reestimate=False):\n",
    "    \"\"\"Rectified image with vanishing point computed using ransac.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: ndarray\n",
    "        Image which has to be rectified.\n",
    "    clip_factor: float, optional\n",
    "        Proportion of image in multiples of image size to be retained if gone\n",
    "        out of bounds after homography.\n",
    "    reestimate: bool\n",
    "        If ransac results are to be reestimated using least squares with\n",
    "        inlers. Turn this off if getting bad results.\n",
    "    Returns\n",
    "    -------\n",
    "    warped_img: ndarray\n",
    "        Rectified image.\n",
    "    \"\"\"\n",
    "    #     if type(image) is not np.ndarray:\n",
    "    #         image = io.imread(image)\n",
    "\n",
    "    # Compute all edgelets.\n",
    "    edgelets1 = compute_edgelets(image)\n",
    "    \n",
    "    vps = []\n",
    "\n",
    "    # Find first vanishing point\n",
    "    vp1 = ransac_vanishing_point(edgelets1, 2000, threshold_inlier=5)\n",
    "    if reestimate:\n",
    "        vp1 = reestimate_model(vp1, edgelets1, 5)\n",
    "\n",
    "    vps.append(vp1)\n",
    "    \n",
    "    \n",
    "    # Remove inlier to remove dominating direction.\n",
    "    edgelets2 = remove_inliers(vp1, edgelets1, 10)\n",
    "\n",
    "    # Find second vanishing point\n",
    "    vp2 = ransac_vanishing_point(edgelets2, 2000, threshold_inlier=5)\n",
    "    if reestimate:\n",
    "        vp2 = reestimate_model(vp2, edgelets2, 5)\n",
    "    vps.append(vp2)\n",
    "\n",
    "    edgelets3 = remove_inliers(vp2, edgelets2, 10)\n",
    "\n",
    "    # Find third vanishing point\n",
    "    vp3 = ransac_vanishing_point(edgelets3, 2000, threshold_inlier=5)\n",
    "    if reestimate:\n",
    "        vp3 = reestimate_model(vp3, edgelets3, 5)\n",
    "    vps.append(vp3)\n",
    "\n",
    "    # Compute the homography and warp\n",
    "    #     warped_img = compute_homography_and_warp(image, vp1, vp2, clip_factor=clip_factor)\n",
    "    \n",
    "    # Print results\n",
    "    for i, vp in enumerate(vps):\n",
    "        print(f'vp{i+1} = [{vp[0]}, {vp[1]}, {vp[2]}]')\n",
    "        vis_model(image, vp)\n",
    "    \n",
    "    return vps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
